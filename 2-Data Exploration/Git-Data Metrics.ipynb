{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community\n",
    "import seaborn as sns\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "#Logger\n",
    "logging.basicConfig(filename='DataMetrics.log', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# PARAMETERS #\n",
    "##############\n",
    "\n",
    "client = MongoClient(username='XXX', password='XXX')\n",
    "\n",
    "DatabaseName = \"Streaming\"\n",
    "CollectionName = \"Campanya\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# COLLECTION METRICS #\n",
    "######################\n",
    "\n",
    "db = client[DatabaseName]\n",
    "tweets = db[CollectionName].find()\n",
    "print(\"Twits Total: {}\".format(tweets.count()))\n",
    "\n",
    "rts=0\n",
    "quotes=0\n",
    "replies=0\n",
    "simples=0\n",
    "\n",
    "for tweet in tweets:\n",
    "    if \"retweeted_status\" in tweet:\n",
    "        rts+=1\n",
    "    elif tweet[\"is_quote_status\"]:\n",
    "        quotes+=1\n",
    "    elif tweet[\"in_reply_to_status_id\"] is not None:\n",
    "        replies+=1\n",
    "    else:\n",
    "        simples+=1\n",
    "               \n",
    "print(\"RTs: \" + str(rts))\n",
    "print(\"Quote: \" + str(quotes))\n",
    "print(\"Reply: \" + str(replies))\n",
    "print(\"Simples: \" + str(simples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# CONVERT TO PANDAS #\n",
    "#####################\n",
    "\n",
    "db = client[DatabaseName]\n",
    "tweets = db[CollectionName].find({}, {'id':1, 'created_at':1, 'user.id':1}, no_cursor_timeout=True, batch_size=1000000)\n",
    "print(\"Twits Total: {}\".format(tweets.count()))\n",
    "\n",
    "tweets_DF = pd.DataFrame(list(tweets))\n",
    "tweets.close()\n",
    "\n",
    "print(\"Number of different tweets:\", tweets_DF['id'].nunique())\n",
    "print(\"Number of different users:\", tweets_DF['user'].apply(lambda x: x.get('id')).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# PLOT TIME ANALYSIS  (NICE!) #\n",
    "###############################\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime as dt\n",
    "\n",
    "'''\n",
    "# color palette\n",
    "colors = [\"#C44E52\", #red\n",
    "          \"#55A868\", #green\n",
    "          \"#FFC400\", #yellow\n",
    "          \"#4C72B0\", #blue\n",
    "          \"#DD8452\", #orange\n",
    "          \"#8172B3\", #purple\n",
    "          \"#64B5CD\", #cyan\n",
    "          \"#937860\", #brown\n",
    "          \"#8C8C8C\", #gray\n",
    "         ]\n",
    "'''\n",
    "\n",
    "tweets_DF['created_at'] = pd.to_datetime(tweets_DF['created_at']).dt.tz_convert('Europe/Madrid')\n",
    "tweets_DF['created_at2'] = pd.to_datetime(tweets_DF['created_at'], infer_datetime_format = \"%d/%m/%Y\", utc  = False)\n",
    "tweets_DF['date'] = tweets_DF.created_at2.dt.date   # we extract the date (year-day-month) from timestamp (created_at)\n",
    "tweets_DF.head(2)\n",
    "\n",
    "start = min(tweets_DF['date'])     # first day\n",
    "end = max(tweets_DF['date'])       # last day\n",
    "\n",
    "# count of interactions per day\n",
    "df_dates  = pd.DataFrame(tweets_DF.groupby('date').agg({'_id':'count'}))\n",
    "df_dates .reset_index(inplace=True)\n",
    "\n",
    "colors = []\n",
    "df_dates2 = df_dates.sort_values(by='_id',axis='index',ascending=False).reset_index().sort_values(by='date',axis='index')\n",
    "for d in df_dates2.date: \n",
    "    if d < dt.datetime(2021, 5, 3).date():\n",
    "        colors.append(\"#55A868\")\n",
    "    elif d < dt.datetime(2021, 5, 4).date():\n",
    "        colors.append(\"#4C72B0\")\n",
    "    else:\n",
    "        colors.append(\"#C44E52\")\n",
    "        \n",
    "''' ANDALUSIA DATES\n",
    "for d in df_dates2.date: \n",
    "    if d < dt.datetime(2022, 6, 18).date():\n",
    "        colors.append(\"#55A868\")\n",
    "    elif d < dt.datetime(2022, 6, 19).date():\n",
    "        colors.append(\"#4C72B0\")\n",
    "    else:\n",
    "        colors.append(\"#C44E52\")\n",
    "'''\n",
    "        \n",
    "plt.figure(figsize=(15,5))\n",
    "ax=sns.barplot(x=df_dates.date, y=df_dates._id, palette=colors)\n",
    "ax.xaxis.set_tick_params(rotation=75)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of tweets')\n",
    "plt.title(\"Tweet distribution grouped by day\")\n",
    "\n",
    "# Create legend.\n",
    "green_patch = mpatches.Patch(color='#55A868', label='Campaign')\n",
    "blue_patch = mpatches.Patch(color='#4C72B0', label='Reflection Journey')\n",
    "red_patch = mpatches.Patch(color='#C44E52', label='Election Day')\n",
    "plt.legend(handles=[blue_patch, green_patch, red_patch], loc=\"upper left\")\n",
    "\n",
    "#plt.savefig(GRAPHICS_DIR + \"total-traffic-timeline\" + FIG_EXTENSION,bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# RT-QUOTE COVERAGE #\n",
    "#####################\n",
    "\n",
    "db = client[DatabaseName]\n",
    "tweets = db[CollectionName].find(no_cursor_timeout=True, batch_size=1000000)\n",
    "print(\"Twits Total: {}\".format(tweets.count()))\n",
    "\n",
    "original_twit = \"\"\n",
    "\n",
    "dictRTCoverage = {}\n",
    "newRTValue = 0\n",
    "counterRT = 0\n",
    "oldMaxRT = 0\n",
    "\n",
    "dictQuoteCoverage = {}\n",
    "newQuoteValue = 0\n",
    "counterQuote = 0\n",
    "oldMaxQuote = 0\n",
    "\n",
    "for tweet in tweets:\n",
    "    if \"retweeted_status\" in tweet:\n",
    "        original_twit = tweet['retweeted_status'] \n",
    "        newRTValue = original_twit[\"retweet_count\"]\n",
    "          \n",
    "        if(original_twit[\"id\"] in dictRTCoverage):\n",
    "            counterRT = dictRTCoverage[original_twit[\"id\"]][0] + 1\n",
    "            oldMaxRT = dictRTCoverage[original_twit[\"id\"]][1]\n",
    "            dictRTCoverage[original_twit[\"id\"]] = [counterRT, max(oldMaxRT, newRTValue)]\n",
    "        else:\n",
    "            dictRTCoverage[original_twit[\"id\"]] = [1, newRTValue]\n",
    "        \n",
    "    elif tweet['is_quote_status']:\n",
    "        if('quoted_status' in tweet):\n",
    "            original_twit = tweet['quoted_status'] \n",
    "            if('quote_count' in original_twit): \n",
    "                newQuoteValue = original_twit[\"quote_count\"]\n",
    "\n",
    "                if(original_twit[\"id\"] in dictQuoteCoverage):\n",
    "                    counterQuote = dictQuoteCoverage[original_twit[\"id\"]][0] + 1\n",
    "                    oldMaxQuote = dictQuoteCoverage[original_twit[\"id\"]][1]\n",
    "                    dictQuoteCoverage[original_twit[\"id\"]] = [counterQuote, max(oldMaxQuote, newQuoteValue)]\n",
    "                else:\n",
    "                    dictQuoteCoverage[original_twit[\"id\"]] = [1, newQuoteValue]\n",
    "\n",
    "tweets.close()\n",
    "\n",
    "totalRTCaptured = 0\n",
    "maxRTCaptured = 0\n",
    "\n",
    "for key, value in dictRTCoverage.items():\n",
    "    totalRTCaptured += value[0]\n",
    "    maxRTCaptured += value[1]\n",
    "\n",
    "print(\"RTs Captured: {}\".format(totalRTCaptured))\n",
    "print(\"Max RTs Captured: {}\".format(maxRTCaptured))\n",
    "print(\"RT Coverage: {:0.2f}%\".format(totalRTCaptured/maxRTCaptured*100))\n",
    "\n",
    "totalQuoteCaptured = 0\n",
    "maxQuoteCaptured = 0\n",
    "\n",
    "for key, value in dictQuoteCoverage.items():\n",
    "    totalQuoteCaptured += value[0]\n",
    "    maxQuoteCaptured += value[1]\n",
    "    \n",
    "print(\"Quotes Captured: {}\".format(totalQuoteCaptured))\n",
    "print(\"Max Quotes Captured: {}\".format(maxQuoteCaptured))\n",
    "print(\"Quote Coverage: {:0.2f}%\".format(totalQuoteCaptured/maxQuoteCaptured*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# ACCOUNT CREATION #\n",
    "####################\n",
    "\n",
    "db = client[DatabaseName]\n",
    "tweets = db[CollectionName].find({}, {'id':1, 'user.id':1, 'user.created_at':1},no_cursor_timeout=True, batch_size=1000000)\n",
    "print(\"Twits Total: {}\".format(tweets.count()))\n",
    "\n",
    "tweets_DF_withDuplicates = pd.DataFrame(list(tweets))\n",
    "tweets.close()\n",
    "print(\"Number of different users:\", tweets_DF_withDuplicates['user'].apply(lambda x: x.get('id')).nunique())\n",
    "tweets_DF_withDuplicates['userId'] = tweets_DF_withDuplicates['user'].apply(lambda x: x.get('id'))\n",
    "\n",
    "tweets_DF = tweets_DF_withDuplicates.drop_duplicates(['userId'])\n",
    "print(\"Number of different users:\", tweets_DF['user'].apply(lambda x: x.get('id')).nunique())\n",
    "print(\"Number of rows in DF without duplicates:\", tweets_DF.shape[0])\n",
    "\n",
    "tweets_DF['user_created_at'] = pd.to_datetime(tweets_DF['user'].apply(lambda x: x.get('created_at')), infer_datetime_format = \"%Y\", utc  = False)\n",
    "tweets_DF['creation_date'] = tweets_DF.user_created_at.dt.year   # we extract the date (year) from timestamp (created_at)\n",
    "\n",
    "start = min(tweets_DF['creation_date'])     # first year\n",
    "end = max(tweets_DF['creation_date'])       # last year\n",
    "\n",
    "# count of interactions per day\n",
    "df_dates  = pd.DataFrame(tweets_DF.groupby('creation_date').agg({'_id':'count'}))\n",
    "df_dates .reset_index(inplace=True)\n",
    "\n",
    "# plot traffic per day, blue color according to traffic volume\n",
    "pal = sns.color_palette(\"Blues_d\", len(df_dates))\n",
    "pal2 = []\n",
    "df_dates2 = df_dates.sort_values(by='_id',axis='index',ascending=False).reset_index().sort_values(by='creation_date',axis='index')\n",
    "for _id in df_dates2.index:\n",
    "    pal2.append(pal[_id])\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax=sns.barplot(x=df_dates.creation_date, y=df_dates._id, palette=pal2)\n",
    "ax.xaxis.set_tick_params(rotation=75)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of accounts')\n",
    "plt.title(\"Number of accounts by creation year\")\n",
    "#plt.savefig(GRAPHICS_DIR + \"total-traffic-timeline\" + FIG_EXTENSION,bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# CUENTAS MATRÍCULA #\n",
    "#####################\n",
    "\n",
    "def is_Matricula (userName):\n",
    "    if(len(userName)>8):\n",
    "        for char in userName[-8:]:\n",
    "            if(not char.isdigit()):\n",
    "                return False\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "db = client[DatabaseName]\n",
    "tweets = db[CollectionName].find({}, {'id':1, 'user.id':1, 'user.screen_name':1, 'user.created_at':1})\n",
    "print(\"Twits Total: {}\".format(tweets.count()))\n",
    "\n",
    "tweets_DF_withDuplicates = pd.DataFrame(list(tweets))\n",
    "print(\"Number of different users:\", tweets_DF_withDuplicates['user'].apply(lambda x: x.get('id')).nunique())\n",
    "tweets_DF_withDuplicates['userId'] = tweets_DF_withDuplicates['user'].apply(lambda x: x.get('id'))\n",
    "\n",
    "tweets_DF = tweets_DF_withDuplicates.drop_duplicates(['userId'])\n",
    "tweets_DF['userName'] = tweets_DF_withDuplicates['user'].apply(lambda x: x.get('screen_name'))\n",
    "tweets_DF['isMatricula'] = tweets_DF['userName'].apply(lambda x: is_Matricula(x))\n",
    "tweets_DF_Matricula = tweets_DF.loc[tweets_DF['isMatricula'] == True]\n",
    "\n",
    "tweets_DF_Matricula['user_created_at'] = pd.to_datetime(tweets_DF_Matricula['user'].apply(lambda x: x.get('created_at')), infer_datetime_format = \"%Y\", utc  = False)\n",
    "tweets_DF_Matricula['creation_date'] = tweets_DF_Matricula.user_created_at.dt.year   # we extract the date (year) from timestamp (created_at)\n",
    "\n",
    "start = min(tweets_DF_Matricula['creation_date'])     # first year\n",
    "end = max(tweets_DF_Matricula['creation_date'])       # last year\n",
    "\n",
    "# count of interactions per day\n",
    "df_dates  = pd.DataFrame(tweets_DF_Matricula.groupby('creation_date').agg({'_id':'count'}))\n",
    "df_dates .reset_index(inplace=True)\n",
    "\n",
    "# plot traffic per day, blue color according to traffic volume\n",
    "pal = sns.color_palette(\"Blues_d\", len(df_dates))\n",
    "pal2 = []\n",
    "df_dates2 = df_dates.sort_values(by='_id',axis='index',ascending=False).reset_index().sort_values(by='creation_date',axis='index')\n",
    "for _id in df_dates2.index:\n",
    "    pal2.append(pal[_id])\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax=sns.barplot(x=df_dates.creation_date, y=df_dates._id, palette=pal2)\n",
    "ax.xaxis.set_tick_params(rotation=75)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of accounts')\n",
    "plt.title(\"Cuentas matricula by creation year\")\n",
    "#plt.savefig(GRAPHICS_DIR + \"total-traffic-timeline\" + FIG_EXTENSION,bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# BUILDING GRAPH #\n",
    "##################\n",
    "\n",
    "FILE_NAME = \"4M-TOTAL.graphml\"\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "db = client[DatabaseName]\n",
    "\n",
    "tweets = db[CollectionName].find(no_cursor_timeout=True, batch_size=1000000)\n",
    "\n",
    "for result in tweets:\n",
    "            uid = result['user']['screen_name']\n",
    "            G.add_node(uid)\n",
    "\n",
    "            if 'retweeted_status' in result:\n",
    "                if G.has_edge(uid, result['retweeted_status']['user']['screen_name']):\n",
    "                    G[uid][result['retweeted_status']['user']['screen_name']]['weight'] += 1.0\n",
    "                else:\n",
    "                    G.add_edge(uid, result['retweeted_status']['user']['screen_name'], weight = 1.0) \n",
    "            elif result['is_quote_status']:\n",
    "                if 'quoted_status' in result:\n",
    "                    if G.has_edge(uid, result['quoted_status']['user']['screen_name']):\n",
    "                        G[uid][result['quoted_status']['user']['screen_name']]['weight'] += 1.0\n",
    "                    else:\n",
    "                        G.add_edge(uid,result['quoted_status']['user']['screen_name'], weight=1.0)\n",
    "            elif result['in_reply_to_status_id'] is not None:\n",
    "                if G.has_edge(uid, result['in_reply_to_screen_name']):\n",
    "                    G[uid][result['in_reply_to_screen_name']]['weight'] += 1.0\n",
    "                else:\n",
    "                    G.add_edge(uid,result['in_reply_to_screen_name'], weight=1.0)\n",
    "\n",
    "tweets.close()                    \n",
    "                    \n",
    "print(\"Nombre de nodes: {}\".format(G.number_of_nodes()))\n",
    "print(\"Nombre d'arestes: {}\".format(G.number_of_edges()))\n",
    "    \n",
    "nx.write_graphml(G, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# GRAPH METRICS #\n",
    "#################\n",
    "\n",
    "#Analitzem alguns valors genèrics del graf, tot i que l'anàlisi es realitzarà principalment a Gephi\n",
    "\n",
    "part = community.best_partition(G.to_undirected())\n",
    "mod = community.modularity(part, G.to_undirected())\n",
    "\n",
    "print(\"S'han detectat {} comunitats: \".format(len(set(part.values()))))\n",
    "\n",
    "comunitats_mes_grans = Counter(part.values()).most_common(5)\n",
    "print(\"Les comunitats més grans són: {}\".format(comunitats_mes_grans))\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "a = {k: str(round(float(v/n*100),2))+\"%\" for k, v in comunitats_mes_grans}\n",
    "print(\"Les comunitats més grans tenen les següents proporcions: {}\".format(a))\n",
    "\n",
    "print(\"La modularitat és: \" + str(mod))\n",
    "\n",
    "degrees = [d for _, d in G.degree()]\n",
    "\n",
    "# Mostrem estadístiques sobre els graus.\n",
    "print('El grau màxim és: {}'.format(max(degrees)))\n",
    "print('El grau mínim és: {}'.format(min(degrees)))\n",
    "print('La mitjana dels graus del graf és: {}'.format(np.mean(degrees)))\n",
    "print('La mediana dels graus del graf és: {}'.format(np.median(degrees)))\n",
    "\n",
    "#Analitzem també valors importants per a valorar quins són els nodes amb més centralitat\n",
    "#Especialment importants són els usuaris amb més grau de sortida, ja que seran analitzats posteriorment per a detectar possibles bots o comportaments extranys\n",
    "centralitat_grau = nx.degree_centrality(G)\n",
    "sorted_g = sorted(centralitat_grau.items(), key=lambda i: i[1], reverse=True)[:20]\n",
    "print(\"Usuaris amb més Centralitat de grau:\")\n",
    "print(sorted_g)\n",
    "\n",
    "indeg = G.in_degree(weight='weight')\n",
    "sorted_indeg = sorted(indeg, key=lambda i: i[1], reverse=True)[:20]\n",
    "print(\"Usuaris amb més grau d'ENTRADA:\")\n",
    "print(sorted_indeg)\n",
    "\n",
    "outdeg = G.out_degree(weight='weight')\n",
    "sorted_outdeg = sorted(outdeg, key=lambda i: i[1], reverse=True)[:50]\n",
    "print(\"Usuaris amb més grau de SORTIDA:\")\n",
    "print(sorted_outdeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
