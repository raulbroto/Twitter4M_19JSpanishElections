{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "from collections.abc import MutableMapping\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community\n",
    "import seaborn as sns\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import time\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import advertools as adv\n",
    "\n",
    "\n",
    "#Logger\n",
    "logging.basicConfig(filename='Separate-General-Partisan-Keywords.log', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb91703",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# PARAMETERS #\n",
    "##############\n",
    "\n",
    "client = MongoClient(username='XXX', password='XXX')\n",
    "\n",
    "DatabaseName = \"Streaming\"\n",
    "tweetCollection = \"Campanya-Interactions-ByKeywordType\"\n",
    "\n",
    "db = client[DatabaseName]\n",
    "tweetCollection = db[tweetCollection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b553eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#  STOPWORDS && EMOJI PATTERN #\n",
    "###############################\n",
    "\n",
    "stopwords_spanish = nltk.corpus.stopwords.words('spanish')\n",
    "stopwords_english = nltk.corpus.stopwords.words('english')\n",
    "stopwords_catalan = adv.stopwords['catalan']\n",
    "\n",
    "custom_stopwords = ['none', '', 'q', 'l', '\\n', 'rt']\n",
    "\n",
    "stopwords = stopwords_spanish + stopwords_english + list(stopwords_catalan)\n",
    "stopwords.extend(custom_stopwords)\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# SET KEYWORD LIST #\n",
    "####################\n",
    "\n",
    "GENERAL_KEYWORD_LIST = [x.lower() for x in [\"#19J\", \"#19Junio\", \"#19JAndalucia\", \"#19JAndalucía\", \"#Elecciones19J\", \"19J\", \n",
    "                                            \"19Junio\", \"#EleccionesAndaluzas\", \"#EleccionesAndalucia\", \"#EleccionesAndalucía\", \n",
    "                                            \"#EleccionesAndalucia2022\", \"#EleccionesAndalucía2022\",\"#DebateRTVE\", \n",
    "                                            \"#ElDebateDecisivo\", \"#DebateDecisivo\"]]\n",
    "\n",
    "PARTISAN_KEYWORD_LIST = [x.lower() for x in [\"#AndaluciaAvanza\", \"#AndalucíaAvanza\", \"#JuanmaPresidente\", \"#SiVotamosGanamos\", \n",
    "                                             \"#AndaluciaQuiereMas\", \"#AndalucíaQuiereMás\", \"#VotaPSOE\", \"#19JAdelante\", \n",
    "                                             \"#AdelanteAndalucia\", \"#AdelanteAndalucía\", \"#EnDefensaPropia\", \n",
    "                                             \"#AndaluciaEnDefensaPropia\", \"#AndalucíaEnDefensaPropia\", \"#Adelante19J\", \n",
    "                                             \"#VotaAdelante19J\", \"#CambioReal\", \"#OlonaPresidenta\", \"#VotaMacarenazo\", \n",
    "                                             \"#VotaMacarenaPresidenta\", \"#PorAndalucia\", \"#PorAndalucía\", \"#VotaTere19J\",\n",
    "                                             \"#AndaluciaLiberal\", \"#AndalucíaLiberal\", \"#ElCambioQueFunciona\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# GET KEYWORD TYPE #\n",
    "####################\n",
    "\n",
    "def clean_tweet(twit_text):\n",
    "    #twit_text_filtered = re.sub(r'[#@]', '', twit_text)\n",
    "    twit_text_filtered = twit_text\n",
    "    twit_text_filtered_2 = re.sub(r'(\\s)http\\S+', '', twit_text_filtered)\n",
    "    twit_text_filtered_3 = emoji_pattern.sub(r'', twit_text_filtered_2)\n",
    "    #twit_text_filtered_3 = twit_text_filtered_2.encode('ascii', 'ignore').decode('ascii') \n",
    "    return twit_text_filtered_3\n",
    "\n",
    "tweets = tweetCollection.find(no_cursor_timeout=True, batch_size=1000000)\n",
    "\n",
    "print(\"OK\")\n",
    "\n",
    "for tweet in tweets:\n",
    "\n",
    "    if 'retweeted_status' in tweet:\n",
    "        if 'extended_tweet' in tweet['retweeted_status']:\n",
    "            clean_text = clean_tweet(str(tweet['retweeted_status']['extended_tweet']['full_text']))\n",
    "        else:\n",
    "            clean_text = clean_tweet(str(tweet['retweeted_status']['text']))\n",
    "            \n",
    "        if tweet['retweeted_status']['is_quote_status']:\n",
    "            if 'quoted_status' in tweet['retweeted_status']:\n",
    "                if 'extended_tweet' in tweet['retweeted_status']['quoted_status']:\n",
    "                    clean_text += \" \" + clean_tweet(str(tweet['retweeted_status']['quoted_status']['extended_tweet']['full_text']))\n",
    "                else:\n",
    "                    clean_text += \" \" + clean_tweet(str(tweet['retweeted_status']['quoted_status']['text']))\n",
    "    elif tweet['is_quote_status']:\n",
    "        if 'extended_tweet' in tweet:\n",
    "            clean_text = clean_tweet(str(tweet['extended_tweet']['full_text']))\n",
    "        else:\n",
    "            clean_text = clean_tweet(str(tweet['text']))\n",
    "        \n",
    "        if 'quoted_status' in tweet:\n",
    "            if 'extended_tweet' in tweet['quoted_status']:\n",
    "                clean_text += \" \" + clean_tweet(str(tweet['quoted_status']['extended_tweet']['full_text']))\n",
    "            else:\n",
    "                clean_text += \" \" + clean_tweet(str(tweet['quoted_status']['text']))                  \n",
    "    elif tweet['in_reply_to_status_id'] is not None:\n",
    "        if 'extended_tweet' in tweet:\n",
    "            clean_text = clean_tweet(str(tweet['extended_tweet']['full_text']))\n",
    "        else:\n",
    "            clean_text = clean_tweet(str(tweet['text']))\n",
    "    else:\n",
    "        if 'extended_tweet' in tweet:\n",
    "            clean_text = clean_tweet(str(tweet['extended_tweet']['full_text']))\n",
    "        else:\n",
    "            clean_text = clean_tweet(str(tweet['text']))\n",
    "    \n",
    "    clean_text = clean_text.replace('\\n',' ').replace('\\t',' ')\n",
    "    \n",
    "    tokens = [w.strip('“”.,;:-():!?-‘’|/•&+* ') for w in re.split(r\"[ ']+\", clean_text.lower())]   \n",
    "    important_tokens = [important_token for important_token in tokens if important_token not in stopwords]\n",
    "    \n",
    "    list_general_keywords = list(set(important_tokens).intersection(GENERAL_KEYWORD_LIST))\n",
    "    list_partisan_keywords = list(set(important_tokens).intersection(PARTISAN_KEYWORD_LIST))\n",
    "       \n",
    "    keyword_type = \"?\"\n",
    "    \n",
    "    if len(list_general_keywords)>0 and len (list_partisan_keywords)>0:\n",
    "        keyword_type = \"BOTH\"\n",
    "    elif len(list_general_keywords)==0 and len (list_partisan_keywords)>0:\n",
    "        keyword_type = \"PARTISAN\"\n",
    "    elif len(list_general_keywords)>0 and len(list_partisan_keywords)==0:\n",
    "        keyword_type = \"GENERAL\"\n",
    "    \n",
    "    try:\n",
    "        tweetCollection.update_one(\n",
    "                                    {'_id': tweet['_id']},\n",
    "                                    {'$set': \n",
    "                                        {\n",
    "                                            'KEYWORD_TYPE': keyword_type,\n",
    "                                            'GENERAL_KEYWORDS': list_general_keywords,\n",
    "                                            'PARTISAN_KEYWORDS': list_partisan_keywords\n",
    "                                        }\n",
    "                                    },\n",
    "                                    upsert=False,\n",
    "                                  )\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        logging.error(\"Fatal exception inserting users in MongoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25535962",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# TWEETS BY KEYWORD TYPE #\n",
    "##########################\n",
    "\n",
    "def load_tweets(collection):\n",
    "    \"\"\"Extracts the tweet bot interaction information\n",
    "    \n",
    "    Keyword arguments:\n",
    "    collection -- MongoDB Tweets' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$project': {\n",
    "                        'KEYWORD_TYPE': True\n",
    "                    }\n",
    "                }, {\n",
    "                    '$group': {\n",
    "                        '_id': {'KEYWORD_TYPE':'$KEYWORD_TYPE'}, \n",
    "                        'count': {\n",
    "                            '$sum': 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    tweets = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    tweets = list(tweets)\n",
    "    print(\"OK; Total combinations:\", len(tweets))\n",
    "    return tweets\n",
    "\n",
    "tweets = load_tweets(tweetCollection)\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df2 = pd.concat([pd.json_normalize(tweets_df['_id']), tweets_df['count']], axis=1)\n",
    "\n",
    "totalTweets = tweets_df2['count'].sum()\n",
    "print(\"TOTAL TWEETS: \" + str(totalTweets))\n",
    "\n",
    "print(tweets_df2.sort_values('count', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89daa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# EXTRACT DATA INTERACTIONS BY COMMUNITY AND KEYWORD TYPE#\n",
    "##########################################################\n",
    "\n",
    "def load_tweets(collection):\n",
    "    \"\"\"Extracts the tweet community interaction information\n",
    "    \n",
    "    Keyword arguments:\n",
    "    collection -- MongoDB Tweets' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$project': {\n",
    "                        'ACTIVE_community': True,\n",
    "                        'KEYWORD_TYPE': True\n",
    "                    }\n",
    "                }, {\n",
    "                    '$group': {\n",
    "                        '_id': {'ACTIVE_community':'$ACTIVE_community', 'KEYWORD_TYPE':'$KEYWORD_TYPE'}, \n",
    "                        'count': {\n",
    "                            '$sum': 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    tweets = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    tweets = list(tweets)\n",
    "    print(\"OK; Total combinations:\", len(tweets))\n",
    "    return tweets\n",
    "\n",
    "tweets = load_tweets(tweetCollection)\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df2 = pd.concat([pd.json_normalize(tweets_df['_id']), tweets_df['count']], axis=1)\n",
    "\n",
    "totalTweets = tweets_df2['count'].sum()\n",
    "print(\"TOTAL TWEETS: \" + str(totalTweets))\n",
    "\n",
    "print(tweets_df2.sort_values('count', ascending=False).head(30).to_string(index=False))\n",
    "\n",
    "tweets_df3 = tweets_df2.groupby(['ACTIVE_community', 'KEYWORD_TYPE']).agg({'count': 'sum'})\n",
    "tweets_df4 = tweets_df3.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "\n",
    "print(tweets_df4.sort_values('ACTIVE_community').to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d02743",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# TWEETS BY SUP_COMMUNITY INTERACTIONS AND KEYWORD #\n",
    "########################################\n",
    "\n",
    "def load_tweets(collection):\n",
    "    \"\"\"Extracts the tweet bot interaction information\n",
    "    \n",
    "    Keyword arguments:\n",
    "    collection -- MongoDB Tweets' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$project': {\n",
    "                        'SUP_community_active': True,\n",
    "                        'KEYWORD_TYPE': True\n",
    "                    }\n",
    "                }, {\n",
    "                    '$group': {\n",
    "                        '_id': {'SUP_community_active':'$SUP_community_active', 'KEYWORD_TYPE':'$KEYWORD_TYPE'}, \n",
    "                        'count': {\n",
    "                            '$sum': 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    tweets = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    tweets = list(tweets)\n",
    "    print(\"OK; Total combinations:\", len(tweets))\n",
    "    return tweets\n",
    "\n",
    "tweets = load_tweets(tweetCollection)\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df2 = pd.concat([pd.json_normalize(tweets_df['_id']), tweets_df['count']], axis=1)\n",
    "\n",
    "totalTweets = tweets_df2['count'].sum()\n",
    "print(\"TOTAL TWEETS: \" + str(totalTweets))\n",
    "\n",
    "print(tweets_df2.sort_values('count', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd08be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# EXTRACT DATA INTERACTIONS BY COMMUNITY (BY TWEET TYPE) #\n",
    "##########################################################\n",
    "\n",
    "tweetType = \"PARTISAN\"\n",
    "\n",
    "def load_tweets(collection):\n",
    "    \"\"\"Extracts the tweet community interaction information\n",
    "    \n",
    "    Keyword arguments:\n",
    "    collection -- MongoDB Tweets' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$match': {\n",
    "                        'KEYWORD_TYPE': tweetType\n",
    "                    }\n",
    "                },{\n",
    "                    '$project': {\n",
    "                        'ACTIVE_community': True,\n",
    "                        'PASSIVE_community': True\n",
    "                    }\n",
    "                }, {\n",
    "                    '$group': {\n",
    "                        '_id': {'ACTIVE_community':'$ACTIVE_community', 'PASSIVE_community':'$PASSIVE_community'}, \n",
    "                        'count': {\n",
    "                            '$sum': 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    tweets = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    tweets = list(tweets)\n",
    "    print(\"OK; Total combinations:\", len(tweets))\n",
    "    return tweets\n",
    "\n",
    "tweets = load_tweets(tweetCollection)\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df2 = pd.concat([pd.json_normalize(tweets_df['_id']), tweets_df['count']], axis=1)\n",
    "\n",
    "totalTweets = tweets_df2['count'].sum()\n",
    "print(\"TOTAL TWEETS: \" + str(totalTweets))\n",
    "\n",
    "print(tweets_df2.sort_values('count', ascending=False).head(30).to_string(index=False))\n",
    "\n",
    "tweets_df3 = tweets_df2.groupby(['ACTIVE_community', 'PASSIVE_community']).agg({'count': 'sum'})\n",
    "tweets_df4 = tweets_df3.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "\n",
    "print(tweets_df4.sort_values('ACTIVE_community').to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# PREPARE HEATMAP DATA #\n",
    "########################\n",
    "\n",
    "COMMUNITIES_LIST = [\"VOX\", \"POR_AND\", \"PSOE\", \"PP\", \"ADELANTE_AND\", \"CS\"]\n",
    "\n",
    "def load_tweets(collection):\n",
    "    \"\"\"Extracts the tweet community interaction information\n",
    "    \n",
    "    Keyword arguments:\n",
    "    collection -- MongoDB Tweets' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$match': {\n",
    "                        'KEYWORD_TYPE': tweetType\n",
    "                    }\n",
    "                },{\n",
    "                    '$project': {\n",
    "                        'ACTIVE_community': True,\n",
    "                        'PASSIVE_community': True\n",
    "                    }\n",
    "                }, {\n",
    "                    '$group': {\n",
    "                        '_id': {'ACTIVE_community':'$ACTIVE_community', 'PASSIVE_community':'$PASSIVE_community'}, \n",
    "                        'count': {\n",
    "                            '$sum': 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    tweets = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    tweets = list(tweets)\n",
    "    print(\"OK; Total combinations:\", len(tweets))\n",
    "    return tweets\n",
    "\n",
    "tweets = load_tweets(tweetCollection)\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df2 = pd.concat([pd.json_normalize(tweets_df['_id']), tweets_df['count']], axis=1)\n",
    "\n",
    "totalTweets = tweets_df2['count'].sum()\n",
    "print(\"TOTAL TWEETS: \" + str(totalTweets))\n",
    "\n",
    "tweets_df3 = tweets_df2[tweets_df2['ACTIVE_community'].isin(COMMUNITIES_LIST)]\n",
    "tweets_df4 = tweets_df3[tweets_df3['PASSIVE_community'].isin(COMMUNITIES_LIST)]\n",
    "\n",
    "#print(tweets_df4.sort_values('count', ascending=False).to_string(index=False))\n",
    "\n",
    "tweets_df5 = tweets_df4.groupby(['ACTIVE_community', 'PASSIVE_community']).agg({'count': 'sum'})\n",
    "tweets_df_test = tweets_df5.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "\n",
    "print(tweets_df_test.sort_values('ACTIVE_community').to_string())\n",
    "\n",
    "tweets_df_test = tweets_df_test.reset_index()  \n",
    "print(tweets_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa25c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# PREPARE HEATMAP DATA 2 #\n",
    "##########################\n",
    "\n",
    "#print(tweets_df_test.index[0])\n",
    "#print(tweets_df_test.name)\n",
    "index_active = COMMUNITIES_LIST\n",
    "index_passive = COMMUNITIES_LIST\n",
    "\n",
    "total_index = list(set(index_active+index_passive))\n",
    "\n",
    "#print(index_active)\n",
    "#print(index_passive)\n",
    "\n",
    "total_index_clean = [x for x in total_index if str(x) != 'nan']\n",
    "\n",
    "final_index = sorted(total_index_clean)\n",
    "\n",
    "print(final_index)\n",
    "\n",
    "\n",
    "matrix = np.zeros((len(final_index),len(final_index)))\n",
    "\n",
    "for active in final_index:\n",
    "    for passive in final_index:\n",
    "        #print(active)\n",
    "        #print(passive)\n",
    "        value = tweets_df_test[(tweets_df_test[\"ACTIVE_community\"]==active) & (tweets_df_test[\"PASSIVE_community\"]==passive)][\"count\"]\n",
    "        matrix[final_index.index(active)][final_index.index(passive)] = value\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# PLOT HEATMAP #\n",
    "################\n",
    "\n",
    "def plot_heatmap(m, x_values, y_values, title, xlabel, ylabel, save_fig=False, label_rotation=None):\n",
    "    \"\"\"\n",
    "        Creates a heatmap image from a numpy matrix.\n",
    "\n",
    "    :param m: 2-dimensional numpy matrix with values to plot\n",
    "    :param x_values: list of strings for xticks\n",
    "    :param y_values: list of strings for yticks\n",
    "    :param title: string, title of the plot\n",
    "    :param xlabel: string, label of the x axis\n",
    "    :param ylabel: string, label of the y axis\n",
    "    :param save_fig: False / \"show\" / figname , do not show imatge / show it inline / write it to pdf (figure name)\n",
    "    :param label_rotation: None / int, whether to rotate x ticks (degrees)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    im = ax.imshow(m.transpose(), origin='lower', cmap='Reds', alpha=0.7, aspect='auto')\n",
    "    #im = ax.imshow(m.transpose(), origin='lower', cmap='jet', alpha=0.7)\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    mt = m.transpose()\n",
    "    for i in range(len(x_values)):\n",
    "        for j in range(len(y_values)):\n",
    "            text = ax.text(j, i, \"{:.2f}%\".format(mt[i, j]), ha=\"center\", va=\"center\", color=\"black\", alpha=1, fontsize=18)\n",
    "\n",
    "    # Named ticks\n",
    "    ax.set_xticks(np.arange(len(x_values)))\n",
    "    ax.set_yticks(np.arange(len(y_values)))\n",
    "    ax.set_xticklabels(x_values)\n",
    "    ax.set_yticklabels(y_values)\n",
    "\n",
    "    # Axis labels\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    # Rotate x labels\n",
    "    if label_rotation:\n",
    "        plt.xticks(rotation=label_rotation)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 24})\n",
    "\n",
    "    # Output result\n",
    "    if not save_fig:\n",
    "        pass\n",
    "    elif save_fig == \"show\":\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_fig + '.pdf', format='pdf', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "######INPUT DATA#####\n",
    "\n",
    "m = matrix\n",
    "x_values = final_index\n",
    "y_values = final_index\n",
    "title = \"Community interactions\"\n",
    "xlabel = \"Passive\"\n",
    "ylabel = \"Active\"\n",
    "save_fig = \"show\"\n",
    "\n",
    "plot_heatmap(m, x_values, y_values, title, xlabel, ylabel, save_fig, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86218345",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# TWEETS BY SUP_COMMUNITY INTERACTIONS #\n",
    "########################################\n",
    "\n",
    "def load_tweets(collection):\n",
    "    \"\"\"Extracts the tweet bot interaction information\n",
    "    \n",
    "    Keyword arguments:\n",
    "    collection -- MongoDB Tweets' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$match': {\n",
    "                        'KEYWORD_TYPE': tweetType\n",
    "                    }\n",
    "                },{\n",
    "                    '$project': {\n",
    "                        'SUP_community_active': True,\n",
    "                        'SUP_community_passive': True\n",
    "                    }\n",
    "                }, {\n",
    "                    '$group': {\n",
    "                        '_id': {'SUP_community_active':'$SUP_community_active', 'SUP_community_passive':'$SUP_community_passive'}, \n",
    "                        'count': {\n",
    "                            '$sum': 1\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    tweets = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    tweets = list(tweets)\n",
    "    print(\"OK; Total combinations:\", len(tweets))\n",
    "    return tweets\n",
    "\n",
    "tweets = load_tweets(tweetCollection)\n",
    "tweets_df = pd.DataFrame(tweets)\n",
    "tweets_df2 = pd.concat([pd.json_normalize(tweets_df['_id']), tweets_df['count']], axis=1)\n",
    "\n",
    "totalTweets = tweets_df2['count'].sum()\n",
    "print(\"TOTAL TWEETS: \" + str(totalTweets))\n",
    "\n",
    "print(tweets_df2.sort_values('count', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe5e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
