{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter\n",
    "from collections.abc import MutableMapping\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community\n",
    "import seaborn as sns\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import time\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import advertools as adv\n",
    "\n",
    "#Logger\n",
    "logging.basicConfig(filename='Text-BioAnalysis.log', format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# PARAMETERS #\n",
    "##############\n",
    "\n",
    "client = MongoClient(username='XXX', password='XXX')\n",
    "\n",
    "DatabaseName = \"Streaming\"\n",
    "CollectionName = \"Users\"\n",
    "\n",
    "db = client[DatabaseName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# GET BIO TEXT  #\n",
    "#################\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def clean_tweet(twit_text):\n",
    "    twit_text_filtered = re.sub(r'[#@]', '', twit_text)\n",
    "    twit_text_filtered_2 = re.sub(r'(\\s)http\\S+', '', twit_text_filtered)\n",
    "    twit_text_filtered_3 = emoji_pattern.sub(r'', twit_text_filtered_2)\n",
    "    #twit_text_filtered_3 = twit_text_filtered_2.encode('ascii', 'ignore').decode('ascii') \n",
    "    return twit_text_filtered_3\n",
    "\n",
    "\n",
    "def load_users(user_collection):\n",
    "\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$match': {\n",
    "                        'description': {            \n",
    "                            '$exists': True\n",
    "                        },\n",
    "                    }\n",
    "                }, {\n",
    "                    '$project': {\n",
    "                        '_id': True, \n",
    "                        'description': True\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    users = user_collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    users = list(users)\n",
    "    print(\"OK; Total users:\", len(users))\n",
    "    return users\n",
    "\n",
    "\n",
    "users_list = load_users (db[CollectionName])\n",
    "\n",
    "text_total = \"\"\n",
    "for user in progress_bar(users_list):\n",
    "    text_total += \" \" + clean_tweet(str(user['description']))\n",
    "            \n",
    "print(len(text_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text_total.split()))\n",
    "\n",
    "tokens = [w.strip('“”.,;:-():!?-‘’|/•&+* ') for w in text_total.lower().split()]\n",
    "\n",
    "# Create counter\n",
    "counts = Counter(tokens)\n",
    "print(len(counts))\n",
    "counts.most_common(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# REMOVE STOPWORDS  #\n",
    "#####################\n",
    "\n",
    "stopwords_spanish = nltk.corpus.stopwords.words('spanish')\n",
    "stopwords_english = nltk.corpus.stopwords.words('english')\n",
    "stopwords_catalan = adv.stopwords['catalan']\n",
    "\n",
    "custom_stopwords = ['none', '', 'q', 'l', '\\n']\n",
    "\n",
    "stopwords = stopwords_spanish + stopwords_english + list(stopwords_catalan)\n",
    "stopwords.extend(custom_stopwords)\n",
    "\n",
    "important_tokens = [important_token for important_token in tokens if important_token not in stopwords]\n",
    "print(len(important_tokens))\n",
    "\n",
    "# Create counter\n",
    "counts = Counter(important_tokens)\n",
    "print(len(counts))\n",
    "counts.most_common(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# BIO ANALYSIS BY COMMUNITY IMPROVED (apostrophe)  #\n",
    "####################################################\n",
    "\n",
    "# MADRID\n",
    "COMMUNITIES_LIST = [\"VOX\", \"PODEMOS\", \"PSOE\", \"PP\", \"MAS_MAD\", \"CS\"]\n",
    "\n",
    "# ANDALUSIA\n",
    "# COMMUNITIES_LIST = [\"VOX\", \"POR_AND\", \"PSOE\", \"PP\", \"ADELANTE_AND\", \"CS\"]\n",
    "\n",
    "def load_users_by_community(user_collection, community):\n",
    "    \"\"\"Extracts the ObjectID and created_at of users\n",
    "    \n",
    "    Keyword arguments:\n",
    "    user_collection -- MongoDB Users' Collection\n",
    "    \"\"\"\n",
    "    pipeline = [\n",
    "                {\n",
    "                    '$match': {\n",
    "                        'community': community,\n",
    "                    }\n",
    "                }, {\n",
    "                    '$project': {\n",
    "                        '_id': True, \n",
    "                        'description': True\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    print(\"Query\", end=\" \")\n",
    "    users = user_collection.aggregate(pipeline, allowDiskUse=True)\n",
    "    print(\"OK; List\", end=\" \")\n",
    "    users = list(users)\n",
    "    print(\"OK; Total users:\", len(users))\n",
    "    return users\n",
    "\n",
    "for community in COMMUNITIES_LIST:\n",
    "    print(\"******************************************************\")\n",
    "    print(\"                      \" + community)\n",
    "    print(\"******************************************************\")\n",
    "    users_by_community_list = load_users_by_community(db[CollectionName], community)\n",
    "\n",
    "    text_total = \"\"\n",
    "    for user in users_by_community_list:\n",
    "        text_total += \" \" + clean_tweet(str(user['description']))\n",
    "\n",
    "    tokens = [w.strip('“”.,;:-():!?-‘’|/•&+* ') for w in re.split(r\"[ ']+\", text_total.lower())]   \n",
    "    important_tokens = [important_token for important_token in tokens if important_token not in stopwords]\n",
    "\n",
    "    counts = Counter(important_tokens)\n",
    "    print(\"Total Tokens: \" + str(len(counts)))\n",
    "    print(counts.most_common(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
